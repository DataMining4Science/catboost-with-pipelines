{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn_pandas import DataFrameMapper, gen_features\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data\n",
    "We are not reading the original data from Kaggel.  \n",
    "The data we are reading is based on the data from Kaggle with small changes:\n",
    "* Random replacement of values with NaNs\n",
    "* Transformations of categorical (int) features to text categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000</td>\n",
       "      <td>66591.000000</td>\n",
       "      <td>66578.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>66589</td>\n",
       "      <td>70000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>women</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>45530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49789</td>\n",
       "      <td>59479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19468.865814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>164.361205</td>\n",
       "      <td>74.210467</td>\n",
       "      <td>128.817286</td>\n",
       "      <td>96.630414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.088129</td>\n",
       "      <td>0.053771</td>\n",
       "      <td>0.803729</td>\n",
       "      <td>0.499700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2467.251667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.226411</td>\n",
       "      <td>14.397678</td>\n",
       "      <td>154.011419</td>\n",
       "      <td>188.472530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.283484</td>\n",
       "      <td>0.225568</td>\n",
       "      <td>0.397179</td>\n",
       "      <td>0.500003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10798.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-150.000000</td>\n",
       "      <td>-70.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17664.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>19703.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>21327.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>23713.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>16020.000000</td>\n",
       "      <td>11000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 age gender        height        weight         ap_hi  \\\n",
       "count   70000.000000  70000  66591.000000  66578.000000  70000.000000   \n",
       "unique           NaN      2           NaN           NaN           NaN   \n",
       "top              NaN  women           NaN           NaN           NaN   \n",
       "freq             NaN  45530           NaN           NaN           NaN   \n",
       "mean    19468.865814    NaN    164.361205     74.210467    128.817286   \n",
       "std      2467.251667    NaN      8.226411     14.397678    154.011419   \n",
       "min     10798.000000    NaN     55.000000     10.000000   -150.000000   \n",
       "25%     17664.000000    NaN    159.000000     65.000000    120.000000   \n",
       "50%     19703.000000    NaN    165.000000     72.000000    120.000000   \n",
       "75%     21327.000000    NaN    170.000000     82.000000    140.000000   \n",
       "max     23713.000000    NaN    250.000000    200.000000  16020.000000   \n",
       "\n",
       "               ap_lo cholesterol    gluc         smoke          alco  \\\n",
       "count   70000.000000       66589   70000  70000.000000  70000.000000   \n",
       "unique           NaN           3       3           NaN           NaN   \n",
       "top              NaN      normal  normal           NaN           NaN   \n",
       "freq             NaN       49789   59479           NaN           NaN   \n",
       "mean       96.630414         NaN     NaN      0.088129      0.053771   \n",
       "std       188.472530         NaN     NaN      0.283484      0.225568   \n",
       "min       -70.000000         NaN     NaN      0.000000      0.000000   \n",
       "25%        80.000000         NaN     NaN      0.000000      0.000000   \n",
       "50%        80.000000         NaN     NaN      0.000000      0.000000   \n",
       "75%        90.000000         NaN     NaN      0.000000      0.000000   \n",
       "max     11000.000000         NaN     NaN      1.000000      1.000000   \n",
       "\n",
       "              active        cardio  \n",
       "count   70000.000000  70000.000000  \n",
       "unique           NaN           NaN  \n",
       "top              NaN           NaN  \n",
       "freq             NaN           NaN  \n",
       "mean        0.803729      0.499700  \n",
       "std         0.397179      0.500003  \n",
       "min         0.000000      0.000000  \n",
       "25%         1.000000      0.000000  \n",
       "50%         1.000000      0.000000  \n",
       "75%         1.000000      1.000000  \n",
       "max         1.000000      1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18393</td>\n",
       "      <td>men</td>\n",
       "      <td>168.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20228</td>\n",
       "      <td>women</td>\n",
       "      <td>156.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>well_above_normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18857</td>\n",
       "      <td>women</td>\n",
       "      <td>165.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17623</td>\n",
       "      <td>men</td>\n",
       "      <td>169.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17474</td>\n",
       "      <td>women</td>\n",
       "      <td>156.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age gender  height  weight  ap_hi  ap_lo        cholesterol    gluc  \\\n",
       "id                                                                          \n",
       "0   18393    men   168.0    62.0    110     80             normal  normal   \n",
       "1   20228  women   156.0    85.0    140     90  well_above_normal  normal   \n",
       "2   18857  women   165.0    64.0    130     70                NaN  normal   \n",
       "3   17623    men   169.0    82.0    150    100             normal  normal   \n",
       "4   17474  women   156.0    56.0    100     60             normal  normal   \n",
       "\n",
       "    smoke  alco  active  cardio  \n",
       "id                               \n",
       "0       0     0       1       0  \n",
       "1       0     0       1       1  \n",
       "2       0     0       0       1  \n",
       "3       0     0       1       1  \n",
       "4       0     0       0       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(seed=42)\n",
    "df_data = pd.read_csv(\"./cardiovascular-disease-dataset/messy/cardio_train.csv\", sep=';', index_col=\"id\")\n",
    "display(df_data.describe(include=\"all\"))\n",
    "display(df_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declerations of all column types and target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_features = [[\"cholesterol\"], [\"gluc\"]]\n",
    "binary_features = [[\"gender\"], [\"smoke\"], [\"alco\"], [\"active\"]]\n",
    "numeric_features = [[\"age\"], [\"height\"], [\"weight\"], [\"ap_hi\"], [\"ap_lo\"]]\n",
    "target = \"cardio\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_data.copy()\n",
    "y = X.pop(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data to train test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create custom transformers for feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blood Pressure Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom transformer responsible for the creation of a new blood pressure categorical feature based on systolic (the number at the top) and diastolic (the number at the bottom) values.  \n",
    "The transformer will create a new categorical feature with values according to the American Heart Association ranges of blood pressure:\n",
    "* normal  \n",
    "* elevated  \n",
    "* high_pressure_stage_1  \n",
    "* high_pressure_stage_2  \n",
    "* hypertensive_crisis  \n",
    "  \n",
    "  \n",
    "![title](images/blood_pressure.png)  \n",
    "Photo from [American Heart Association](https://www.heart.org/-/media/data-import/downloadables/pe-abh-what-is-high-blood-pressure-ucm_300310.pdf?la=en&hash=CAC0F1D377BDB7BC3870993918226869524AAC3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BloodPressureTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # Systolic and diastolic blood pressure ranges based on the American Heart Association\n",
    "        self.systolic_ranges = [-np.inf, 119, 129, 139, 180, np.inf]\n",
    "        self.diastolic_ranges = [-np.inf, 79, 89, 120, np.inf]\n",
    "        \n",
    "        # Blood pressure categories\n",
    "        self.blood_pressure_category = [\"normal\", \"elevated\", \"high_pressure_stage_1\", \"high_pressure_stage_2\", \"hypertensive_crisis\"]\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Copy the data so we will not change the original instance\n",
    "        df_blood_pressure = X.copy()\n",
    "        \n",
    "        # Break down ranges of systolic values to categories\n",
    "        df_blood_pressure[\"systolic\"] = pd.cut(df_blood_pressure[\"ap_hi\"], self.systolic_ranges, labels=[\"<120\", \"120-129\", \"130-139\", \"140-180\", \">180\"])\n",
    "        \n",
    "        # Break down ranges of diastolic values to categories\n",
    "        df_blood_pressure[\"diastolic\"] = pd.cut(df_blood_pressure[\"ap_lo\"], self.diastolic_ranges, labels=[\"<79\", \"80-89\", \"90-120\", \">120\"])\n",
    "        \n",
    "        # Combine ranges from systolic and diastolic features to determine the category of the blood pressure feature\n",
    "        df_blood_pressure.loc[(df_blood_pressure[\"systolic\"] == \"<120\") &\n",
    "                              (df_blood_pressure[\"diastolic\"] == \"<79\"), \"blood_pressure\"] = self.blood_pressure_category[0]\n",
    "        \n",
    "        df_blood_pressure.loc[(df_blood_pressure[\"systolic\"] == \"120-129\") &\n",
    "                              (df_blood_pressure[\"diastolic\"] == \"<79\"), \"blood_pressure\"] = self.blood_pressure_category[1]\n",
    "        \n",
    "        df_blood_pressure.loc[(df_blood_pressure[\"systolic\"] == \"130-139\") |\n",
    "                              (df_blood_pressure[\"diastolic\"] == \"80-89\"), \"blood_pressure\"] = self.blood_pressure_category[2]\n",
    "        \n",
    "        df_blood_pressure.loc[(df_blood_pressure[\"systolic\"] == \"140-180\") |\n",
    "                              (df_blood_pressure[\"diastolic\"] == \"90-120\"), \"blood_pressure\"] = self.blood_pressure_category[3]\n",
    "        \n",
    "        df_blood_pressure.loc[(df_blood_pressure[\"systolic\"] == \">180\") |\n",
    "                              (df_blood_pressure[\"diastolic\"] == \">120\"), \"blood_pressure\"] = self.blood_pressure_category[4]\n",
    "        \n",
    "        # Return blood pressure feature as a dataframe with one column\n",
    "        return df_blood_pressure[[\"blood_pressure\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unhealty Lifestyle Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom transformer responsible for the creation of a new \"unhealty lifestyle\" feature.  \n",
    "This is a boolean feature representing the use of cigarettes, alcohol, and physical inactivity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnhealtyLifestyleTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Copy the data so we will not change the original instance\n",
    "        df_unhealty_lifestyle = X.copy()\n",
    "        \n",
    "        # If you smoke or use alcohol or don't do physical activity, you maintain an unhealty lifestyle!\n",
    "        df_unhealty_lifestyle[\"unhealty_lifestyle\"] = df_unhealty_lifestyle[\"smoke\"] | df_unhealty_lifestyle[\"alco\"] | (~df_unhealty_lifestyle[\"active\"])\n",
    "        \n",
    "        # Return unhealty lifestyle feature as a dataframe with one column\n",
    "        return df_unhealty_lifestyle[[\"unhealty_lifestyle\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of DataFrameMapper transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define the pipeline of transformations and the raw features we need to complete the creation and processing of the new features and the original features.  \n",
    "We will pass this to the DataFrameMapper class of the sklearn-pandas package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['ap_hi', 'ap_lo'],\n",
       " [BloodPressureTransformer(),\n",
       "  SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "         strategy='most_frequent', verbose=0),\n",
       "  OneHotEncoder(categorical_features=None, categories=None,\n",
       "         dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "         n_values=None, sparse=True)],\n",
       " {'alias': 'blood_pressure'})"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input features \"ap_hi\", \"ap_lo\".\n",
    "# Steps:\n",
    "#    BloodPressureTransformer - create blood pressure feature based on \"ap_hi\", \"ap_lo\".\n",
    "#    SimpleImputer - fill nans with the most frequent value.\n",
    "#    OneHotEncoder - encode categorical values as a one-hot numeric array.\n",
    "gen_blood_pressure = (\n",
    "    [\"ap_hi\", \"ap_lo\"],\n",
    "    [\n",
    "        BloodPressureTransformer(),\n",
    "        SimpleImputer(strategy=\"most_frequent\"),\n",
    "        OneHotEncoder()\n",
    "    ],\n",
    "    {\"alias\": \"blood_pressure\"}\n",
    ")\n",
    "\n",
    "gen_blood_pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['smoke', 'alco', 'active'],\n",
       " [UnhealtyLifestyleTransformer(),\n",
       "  SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "         strategy='most_frequent', verbose=0)],\n",
       " {'alias': 'unhealty_lifestyle'})"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input features [\"smoke\", \"alco\", \"active\"].\n",
    "# Steps:\n",
    "#    UnhealtyLifestyleTransformer - create unhealty lifestyle feature based on \"smoke\", \"alco\", \"active\".\n",
    "#    SimpleImputer - fill nans with the most frequent value.\n",
    "gen_unhealty_lifestyle = (\n",
    "    [\"smoke\", \"alco\", \"active\"],\n",
    "    [\n",
    "        UnhealtyLifestyleTransformer(),\n",
    "        SimpleImputer(strategy=\"most_frequent\")\n",
    "    ],\n",
    "    {\"alias\": \"unhealty_lifestyle\"}\n",
    ")\n",
    "\n",
    "gen_unhealty_lifestyle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the same transformers for multiple columns with gen_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['cholesterol'],\n",
       "  [SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "          strategy='most_frequent', verbose=0),\n",
       "   OneHotEncoder(categorical_features=None, categories=None,\n",
       "          dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "          n_values=None, sparse=True)]),\n",
       " (['gluc'], [SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "          strategy='most_frequent', verbose=0),\n",
       "   OneHotEncoder(categorical_features=None, categories=None,\n",
       "          dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "          n_values=None, sparse=True)])]"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input features [[\"cholesterol\"], [\"gluc\"]] (The columns are now list of lists because we want to send 2-dimentional DataFrame to each of the transformers).\n",
    "# Steps:\n",
    "#    SimpleImputer - fill nans with the most frequent value.\n",
    "#    OneHotEncoder - encode categorical values as a one-hot numeric array.\n",
    "gen_category = gen_features(\n",
    "    columns=category_features,\n",
    "    classes=[\n",
    "        {\n",
    "            \"class\": SimpleImputer,\n",
    "            \"strategy\": \"most_frequent\"\n",
    "        },\n",
    "        {\n",
    "            \"class\": OneHotEncoder\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "gen_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['gender'], [SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "          strategy='most_frequent', verbose=0),\n",
       "   OrdinalEncoder(categories='auto', dtype=<class 'numpy.float64'>)]),\n",
       " (['smoke'], [SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "          strategy='most_frequent', verbose=0),\n",
       "   OrdinalEncoder(categories='auto', dtype=<class 'numpy.float64'>)]),\n",
       " (['alco'], [SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "          strategy='most_frequent', verbose=0),\n",
       "   OrdinalEncoder(categories='auto', dtype=<class 'numpy.float64'>)]),\n",
       " (['active'], [SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "          strategy='most_frequent', verbose=0),\n",
       "   OrdinalEncoder(categories='auto', dtype=<class 'numpy.float64'>)])]"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input features [[\"gender\"], [\"smoke\"], [\"alco\"], [\"active\"]] (The columns are now list of lists because we want to send 2-dimentional DataFrame to each of the transformers).\n",
    "# Steps:\n",
    "#    SimpleImputer - fill nans with the most frequent value.\n",
    "#    OrdinalEncoder - encode categorical features as an integer array.\n",
    "gen_binary = gen_features(\n",
    "    columns=binary_features,\n",
    "    classes=[\n",
    "        {\n",
    "            \"class\": SimpleImputer,\n",
    "            \"strategy\": \"most_frequent\"\n",
    "        },\n",
    "        {\n",
    "            \"class\": OrdinalEncoder\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "gen_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['age'],\n",
       "  [SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',\n",
       "          verbose=0),\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)]),\n",
       " (['height'],\n",
       "  [SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',\n",
       "          verbose=0),\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)]),\n",
       " (['weight'],\n",
       "  [SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',\n",
       "          verbose=0),\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)]),\n",
       " (['ap_hi'],\n",
       "  [SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',\n",
       "          verbose=0),\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)]),\n",
       " (['ap_lo'],\n",
       "  [SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',\n",
       "          verbose=0),\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)])]"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input features [[\"age\"], [\"height\"], [\"weight\"], [\"ap_hi\"], [\"ap_lo\"]] (The columns are now list of lists because we want to send 2-dimentional DataFrame to each of the transformers).\n",
    "# Steps:\n",
    "#    SimpleImputer - fill nans with the mean value.\n",
    "#    StandardScaler - standardize features by removing the mean and scaling to unit variance.\n",
    "gen_numeric = gen_features(\n",
    "    columns=numeric_features,\n",
    "    classes=[\n",
    "        {\n",
    "            \"class\": SimpleImputer,\n",
    "            \"strategy\": \"mean\"\n",
    "        },\n",
    "        {\n",
    "            \"class\": StandardScaler\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "gen_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrameMapper Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define the course of action of the DataFrameMapper and indicate that the input and output will be Pandas Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_mapper = DataFrameMapper(\n",
    "    [\n",
    "        gen_blood_pressure,\n",
    "        gen_unhealty_lifestyle,\n",
    "        *gen_category,\n",
    "        *gen_binary,\n",
    "        *gen_numeric,\n",
    "    ],\n",
    "    input_df=True,\n",
    "    df_out=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection = DataFrameMapper(\n",
    "    [(\n",
    "        preprocess_mapper.transformed_names_,\n",
    "        SelectFromModel(RandomForestClassifier(n_estimators=100, max_depth=10))\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess_mapper),\n",
    "    (\"feature_selection\", feature_selection),\n",
    "    (\"estimator\", RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    \"estimator__n_estimators\": [200, 500],\n",
    "    \"estimator__max_features\": ['auto', 'sqrt', 'log2'],\n",
    "    \"estimator__max_depth\": [4, 5, 6, 7, 8],\n",
    "    \"estimator__criterion\":['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv_estimator = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1)\n",
    "gscv_estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator__criterion': 'entropy', 'estimator__max_depth': 8, 'estimator__max_features': 'log2', 'estimator__n_estimators': 200}\n",
      "0.7254489795918367\n"
     ]
    }
   ],
   "source": [
    "print(gscv_estimator.best_params_)    \n",
    "print(gscv_estimator.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = gscv_estimator.predict(X_test)\n",
    "display(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.7256190476190476\n",
      "roc_auc_score: 0.7257726793673044\n",
      "precision_score: 0.7475386050367914\n",
      "recall_score: 0.6844102856058449\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy_score: {accuracy_score(y_test, preds)}\")\n",
    "print(f\"roc_auc_score: {roc_auc_score(y_test, preds)}\")\n",
    "print(f\"precision_score: {precision_score(y_test, preds)}\")\n",
    "print(f\"recall_score: {recall_score(y_test, preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
